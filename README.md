# üè¶ Predicci√≥n de Aceptaci√≥n de Productos Bancarios con Deep Learning y XAI

> **Un proceso sistem√°tico mediante Redes Neuronales, Modelos de Ensamble y T√©cnicas de Explicabilidad.**

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-Keras-orange)
![Scikit-Learn](https://img.shields.io/badge/Sklearn-Machine%20Learning-yellow)
![SHAP](https://img.shields.io/badge/XAI-SHAP-green)

## üìã Descripci√≥n del Proyecto

Este proyecto aborda el desaf√≠o de predecir si un cliente suscribir√° un dep√≥sito a plazo fijo bas√°ndose en datos de campa√±as de marketing directo de una instituci√≥n bancaria portuguesa.

Se sigue la metodolog√≠a **CRISP-DM**, implementando un flujo de trabajo robusto que incluye limpieza de datos, ingenier√≠a de caracter√≠sticas, reducci√≥n de dimensionalidad (PCA), balanceo de clases (SMOTE) y la comparaci√≥n de arquitecturas de Machine Learning cl√°sico vs. Deep Learning y Stacking.

**Autores:**
* Andr√©s Encalada
* Karen Ortiz

## üìä Dataset

El conjunto de datos proviene del repositorio UCI Machine Learning: **Bank Marketing Dataset**.
* **Instancias:** 41,188
* **Variables:** 20 (Demogr√°ficas, Contexto Socioecon√≥mico y Detalles de contacto).
* **Target:** `y` (Suscripci√≥n al dep√≥sito: 'yes'/'no').

## üõ†Ô∏è Tecnolog√≠as y Librer√≠as

* **Python 3**
* **Manipulaci√≥n de Datos:** Pandas, NumPy.
* **Machine Learning:** Scikit-learn (Pipeline, ColumnTransformer, PCA).
* **Balanceo de Datos:** Imbalanced-learn (SMOTE).
* **Deep Learning:** TensorFlow / Keras.
* **Explicabilidad (XAI):** SHAP.
* **Visualizaci√≥n:** Matplotlib, Seaborn.

## ‚öôÔ∏è Metodolog√≠a del Pipeline

### 1. Preprocesamiento e Ingenier√≠a de Caracter√≠sticas
* **Limpieza:** Manejo de valores 'unknown' y eliminaci√≥n de duplicados.
* **Transformaci√≥n:**
    * *Num√©ricas:* Imputaci√≥n (mediana) y Estandarizaci√≥n (StandardScaler).
    * *Categ√≥ricas:* Codificaci√≥n One-Hot y Ordinal.
* **Reducci√≥n de Dimensionalidad:** Aplicaci√≥n de **PCA** conservando el 95% de la varianza (reducci√≥n de 47 a 22 features).
* **Balanceo:** Aplicaci√≥n de **SMOTE** en el conjunto de entrenamiento para mitigar el desbalance de clases.

### 2. Modelado (Arquitecturas Evaluadas)
Se dise√±aron y compararon tres estrategias:
1.  **L√≠nea Base (Baseline):** Comparaci√≥n entre **KNN** y **Random Forest**. (Ganador: Random Forest).
2.  **Deep Learning (Propuesta):** Red Neuronal Artificial (ANN) con capas densas, activaci√≥n ReLU y Dropout para regularizaci√≥n.
3.  **H√≠brida (Stacking):** Un ensamble que combina las predicciones de RF, KNN y ANN utilizando una Regresi√≥n Log√≠stica como meta-modelo.

## üèÜ Resultados y Evaluaci√≥n

El modelo de **Red Neuronal** fue seleccionado como el mejor modelo para producci√≥n debido a su capacidad superior de generalizaci√≥n (AUC) y su equilibrio en la matriz de confusi√≥n (menor cantidad de clientes potenciales perdidos).

| Modelo | AUC Score | F1-Score | Observaci√≥n |
| :--- | :---: | :---: | :--- |
| **Red Neuronal (ANN)** | **0.9423** | **0.6305** | **Mejor rendimiento global y operativo.** |
| Random Forest | 0.9357 | 0.6143 | Baseline s√≥lido. |
| Stacking Ensemble | 0.9342 | 0.5756 | Demasiado conservador (muchos Falsos Negativos). |

### Impacto de Negocio (Matriz de Confusi√≥n)
La Red Neuronal logr√≥ reducir significativamente los **Falsos Negativos** (clientes interesados que el modelo ignor√≥), captando un **41% m√°s de oportunidades de venta** en comparaci√≥n con el modelo de Stacking.

## üîç Explicabilidad (XAI) con SHAP

Se utiliz√≥ **SHAP (SHapley Additive exPlanations)** para interpretar las decisiones del modelo.
* **Variable m√°s influyente:** `duration` (Duraci√≥n de la llamada). A mayor duraci√≥n, mayor probabilidad de √©xito.
* **Factores Macroecon√≥micos:** `euribor3m` y `nr.employed` juegan un papel crucial, indicando que el contexto econ√≥mico afecta la decisi√≥n del cliente.

## üöÄ Instalaci√≥n y Uso

1.  Clona el repositorio:
    ```bash
    git clone [https://github.com/Karenop4/prediccion-de-aceptacion-de-productos-bancarios.git](https://github.com/Karenop4/prediccion-de-aceptacion-de-productos-bancarios.git)
    ```
2.  Instala las dependencias:
    ```bash
    pip install pandas numpy scikit-learn tensorflow shap imbalanced-learn matplotlib seaborn
    ```
3.  Ejecuta el notebook `Interciclo.ipynb` en Jupyter o Google Colab.

## üìÑ Licencia
Este proyecto es para fines educativos y acad√©micos.
